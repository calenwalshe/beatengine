# Techno Rhythm Engine — Implementation Roadmap (.roadmap.md)

> A concise, execution-ready plan Codex can follow to scaffold, build, and validate a **minimal-parameter generative rhythm engine** from a ~1,000 MIDI techno corpus.

---

## 0) Mission & Non-Negotiables

**Mission:** Learn the statistical grammar of techno drum patterns and ship an interpretable generator controlled by a small set of musical parameters that reproduces corpus-level variation.

**Principles**
- Deterministic runs (seeded RNG, fixed grids); reproducible artifacts.
- Licensing tracked per file; no redistribution of proprietary MIDI.
- Parameter **identifiability**: monotone knob → behavior mappings, sensitivity tests.
- Held-out validation split by **source pack** to avoid leakage.

**Repo Root**
```
data_raw/  data_proc/  features/  generator/  fit/  eval/  ui/  notebooks/  utils/  docs/
```

---

## 1) Environment & Scaffolding (Day 0–1)

**Tasks**
- [E-1] Initialize repo; add `.gitignore`, `README.md`, `requirements.txt`.
- [E-2] Create empty module stubs per directory with docstrings.
- [E-3] Set up fast Python tooling with `uv` (or venv+pip fallback).

**Commands**
```bash
# Option A: uv (fast)
curl -LsSf https://astral.sh/uv/install.sh | sh
uv venv
uv pip install -r requirements.txt

# Option B: venv
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

**Acceptance**
- `import generator, fit, eval` works.
- `python -c "import numpy, pretty_midi"` succeeds.

**Deliverables**
- `README.md` (project goals + folder map)
- `requirements.txt` (mido, pretty_midi, numpy, scipy, pandas, scikit-learn, optuna, matplotlib, tqdm, torch, pot)

---

## 2) Data Ingestion & Normalization Pipeline (Week 1)

**Objective:** Convert arbitrary techno drum MIDIs into canonical 5-instrument, 4-bar, 16th-grid matrices with velocities and optional microtiming.

**Tasks**
- [D-1] Implement `/utils/config.py` (instrument map, TARGET_BPM=128, GRID_STEPS=64).
- [D-2] `/data_proc/parse_midi.py`:
  - Load `.mid` (pretty_midi/mido), detect drum tracks.
  - Map to `{kick,snare,hh_closed,hh_open,cymbal}`.
  - Quantize to 16th grid; store Δt (ms) residuals.
  - Enforce choke: OH at t ⇒ CH[t]=0.
  - Normalize tempo to 128 BPM; rotate so first strong kick aligns to step 0 (store rotation).
  - Segment long loops to 4 bars; save as `.npz` `{X,V,dt,meta}`.
- [D-3] Dedupe:
  - Exact hash on `(X, V>0)` plus all cyclic rotations.
  - Near-duplicate LSH on flattened `X` bits (5×64).
- [D-4] CLI wrapper:
  ```bash
  python data_proc/parse_midi.py --input data_raw --output data_proc --dedupe 1
  ```

**Acceptance**
- For 5 sample MIDIs in `data_raw/`, `data_proc/*.npz` exist with shapes `(5,64)`.
- Rotation, bpm, mapping, license fields present in `meta`.
- Dedupe log printed; duplicates removed.

**Artifacts**
- `data_proc/*.npz` (canonical clips)
- `docs/data_pipeline.md` (short spec)

---

## 3) Feature Extraction & Corpus “Grammar” (Week 2)

**Objective:** Produce per-clip features + corpus targets for fitting and analysis.

**Tasks**
- [F-1] `/features/extract_features.py`: compute
  - Per-instrument density, offbeat ratios (8th/16th), velocity stats (8-bin hist, mean/std).
  - n-gram transitions (order 1–2) with Dirichlet smoothing.
  - Autocorrelation peaks at lags {1,2,3,4,6,8,12,16,32}.
  - Cross-instrument co-occurrence (kick↔hat; lead/lag ±2 steps).
  - Swing/microtiming summaries from `dt`.
- [F-2] Save per-clip feature rows → `features/features.parquet`.
- [F-3] `/notebooks/eda.ipynb` quick visuals: density histograms; kick-hat phase; PCA/NMF (K=2–4).
- [F-4] Aggregate **corpus targets** (pooled histograms, mean transitions) → `features/corpus_targets.parquet`.

**Acceptance**
- `features/features.parquet` has ≥ 20 columns; row count equals `data_proc` clips.
- PCA/NMF plots exported to `docs/plots/*.png`.

**Artifacts**
- `features/features.parquet`
- `features/corpus_targets.parquet`
- `docs/techno_grammar.md` (2-page memo with key plots)

---

## 4) Procedural Generator v1 (Week 3)

**Objective:** Deterministic rule-based generator with interpretable parameters outputting canonical `(X,V,dt)`.

**Minimal Parameter Set (initial)**
- Global: `swing_16`, `humanize_ms`, `intensity`, `rotation`
- Kick: `kick_density`, `kick_syncopation`
- Snare: `backbeat_strength`, `snare_sync`
- Hats: `hat_density`, `openness`, `ratchet_prob`
- Cymbal: `ride_density` (optional), `crash_prob` (optional)

**Tasks**
- [G-1] `/generator/engine.py`:
  - Euclidean/Bjorklund pulses for kicks with syncopation bias.
  - Backbeat mask + syncopated neighbors for snare.
  - CH grid from 8th/16th mixture tuned by `hat_density`; promote OH by `openness`; choke.
  - Ratchets: duplicate within step to neighbors (grid-safe approximation).
  - Apply swing time-warping (16th); add `humanize_ms`; velocity templates × `intensity`.
- [G-2] MIDI export via pretty_midi.
- [G-3] Unit tests in `/generator/tests/`:
  - CH/OH never coincide same step.
  - Monotone checks: ↑`hat_density` ⇒ ↑CH hits; ↑`backbeat_strength` ⇒ ↑snare at {4,12}.

**Acceptance**
- `python ui/console.py --out demo.mid` writes a 4-bar loop; audible swing/hat changes when knobs vary.
- Tests pass.

**Artifacts**
- `generator/engine.py`, `generator/tests/test_monotone.py`
- `generator/presets/*.json` (default θ)

---

## 5) Objective & Fitting Loop (Week 4)

**Objective:** Fit θ against corpus targets using simulation-based optimization.

**Tasks**
- [O-1] `/eval/metrics.py`:
  - Jensen–Shannon for histograms; n-gram Frobenius loss; ACF L2; MMD (Gaussian kernel).
- [O-2] `/fit/optimize.py`:
  - For a given θ, generate B=128 patterns over fixed seed set; compute `F_gen(θ)`.
  - Composite distance:
    ```
    D = Σ w_js·JS + w_ng·||T||_F + w_acf·||acf||_2 + w_mmd·MMD^2 + w_x·KL(cooc) + λ||θ-θ0||_2
    ```
  - Optimizers: CMA-ES or Optuna TPE; log to CSV.
- [O-3] Train/valid/test split by **source pack**; evaluate on held-out.

**Acceptance**
- Convergence curve decreases and stabilizes.
- Core histogram errors ≤ 5–8% on validation; generalizes to test.

**Artifacts**
- `fit/runs/*/best_theta.json`
- `eval/reports/*/fit_summary.md` (plots & metrics)

---

## 6) Parameter Reduction & Identifiability (Week 5)

**Objective:** Minimize control surface with negligible loss in fit.

**Tasks**
- [R-1] Global sensitivity (Sobol/Morris) around best θ.
- [R-2] Profile-likelihood: vary one parameter, re-optimize others; measure ΔD.
- [R-3] Merge/drop low-impact or collinear knobs (e.g., unify `hat_rate` into `hat_density`).
- [R-4] Refit with reduced set; compare metrics and listening tests.

**Acceptance**
- Reduced set (≈ 8–10 knobs) with ΔD within ε; monotone tests still pass.
- Report documents which knobs were dropped/merged and why.

**Artifacts**
- `fit/runs/*/theta_min.json`
- `docs/parameter_reduction.md`

---

## 7) Evaluation & UI (Week 6)

**Objective:** Quantitative reports + quick audition UI.

**Tasks**
- [V-1] Quant:
  - Histogram overlays; n-gram matrices; ACF comparisons for (train/valid/test).
  - Bootstrap corpus targets for 95% CI; assert generator inside bands on key stats.
- [V-2] Perceptual:
  - Export sets: **Real**, **Gen(θ-min)**, **Ablated(−param)**, **Randomized** for MUSHRA-style listening.
- [V-3] Minimal UI:
  - `/ui/console.py` arg-parsing for θ JSON, seed, bpm, output MIDI.
  - (Optional) web/Tone.js slider demo.

**Acceptance**
- Eval report renders; MIDI packs playable; auditors can hear smooth parameter sweeps.

**Artifacts**
- `eval/reports/final_report.md`
- `ui/console.py`, `ui/examples/*.mid`

---

## 8) Documentation & Release (Week 7)

**Tasks**
- [P-1] `docs/method.md`: data → features → generator → fitting → reduction.
- [P-2] `docs/reproduce.md`: end-to-end commands, seeds, environment.
- [P-3] Release **derived** dataset (features only) if licenses disallow MIDI redistribution.

**Acceptance**
- Fresh clone + reproduce guide yields identical metrics (within tolerance).

---

## 9) Risk Log & Mitigations

- **License risk:** store `license.json` per clip; exclude ND packs.
- **Duplicates:** rotation-invariant hashing; LSH threshold for near-dupes.
- **Leakage:** split by pack; verify zero filename overlap.
- **Non-identifiable knobs:** detect via profile-likelihood and drop/merge.
- **Overfitting to packs:** report per-pack residuals; ensure balance.

---

## 10) Checklists (for Codex Execution)

**Create Files**
- `utils/config.py`
- `data_proc/parse_midi.py`
- `features/extract_features.py`
- `generator/engine.py`
- `generator/tests/test_monotone.py`
- `eval/metrics.py`
- `fit/optimize.py`
- `ui/console.py`
- `docs/{data_pipeline.md, techno_grammar.md, parameter_reduction.md, method.md, reproduce.md}`

**Wire CLI Entrypoints**
```bash
python data_proc/parse_midi.py --input data_raw --output data_proc
python -m features.extract_features --in data_proc --out features/features.parquet
python fit/optimize.py --targets features/corpus_targets.parquet --algo cmaes --evals 600
python ui/console.py --theta generator/presets/default.json --seed 42 --out demo.mid
```

**Unit Tests (pytest)**
- CH/OH mutual exclusion.
- Monotone density/backbeat checks.
- Deterministic output under fixed seed.

---

## 11) Milestones & Tags

- **M1_DataReady** (end Week 1): canonical NPZ + dedupe + metadata.
- **M2_FeaturesReady** (end Week 2): features parquet + corpus targets + EDA plots.
- **M3_GenV1** (end Week 3): generator produces valid MIDI; tests pass.
- **M4_FitV1** (end Week 4): θ found; validation within 5–8%.
- **M5_MinParams** (end Week 5): reduced knob set; ΔD≤ε.
- **M6_Eval+UI** (end Week 6): reports + audition UI.
- **M7_Docs** (end Week 7): full reproduction docs.

Tag repo at each milestone:
```bash
git tag -a M1_DataReady -m "Data pipeline complete"
# … then push tags
git push --tags
```

---

## 12) Quick Start Runbook

```bash
# 1) Install
uv venv && uv pip install -r requirements.txt

# 2) Ingest a few MIDIs
python data_proc/parse_midi.py --input data_raw --output data_proc

# 3) Extract features
python -m features.extract_features --in data_proc --out features/features.parquet

# 4) Generate a loop
python ui/console.py --theta generator/presets/default.json --out demo.mid

# 5) Fit parameters
python fit/optimize.py --targets features/corpus_targets.parquet --algo cmaes --evals 400
```

---

## 13) Definition of Done

- Minimal parameter set (≈ 8–10 knobs) with **documented** semantics and **monotone** effects.
- Quantitative match to corpus targets within thresholds on held-out.
- Reproducible pipeline and evaluation; demo MIDI examples; clear docs.

---
